---
title: "Intro to rtweet: Collecting Twitter Data"
author: "Michael W. Kearney"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Intro to rtweet}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This vignettes provides a *very* quick tour of rtweet: Collecting Twitter Data.

## Accessing Twitter's API

Before you can start collecting data, you must first obtain a user access token. 
To do this, I recommend following the vignette on [obtaining and setting up user access tokens](https://github.com/mkearney/rtweet/blob/master/vignettes/tokens.Rmd). 
However, if you're in a hurry, the [quick guide found here](https://github.com/mkearney/rtweet/blob/master/README.md) works as well.

## Install and Load

```{r, eval=FALSE}
if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}
devtools::install_github("mkearney/rtweet")
library(rtweet)
```

## Retrieving Tweets

```{r, eval=FALSE}
# search for 500 tweets using the #rstats hashtag
team_rstats <- search_tweets("#rstats", n = 500)
team_rstats

# extract data on the users who posted the tweets
users_data(team_rstats)

# return 200 tweets from @KyloR3n's timeline
kylo_is_a_mole <- get_timeline("KyloR3n", n = 200)
kylo_is_a_mole

# extract emo kylo ren's user data
users_data(kylo_is_a_mole)

# stream tweets mentioning @HillaryClinton for 2 minutes (120 sec)
imwithher <- stream_tweets("HillaryClinton", timeout = 120)
imwithher

# extract data on the users who posted the tweets
users_data(imwithher)
```

## Retrieving Users

```{r, eval=FALSE}
# search for 500 users using "social science" as a keyword
harder_science <- search_users("social science", n = 500)
harder_science

# extract most recent tweets data from the social scientists
tweets_data(harder_science)

# lookup users by screen_name or user_id
users <- c("KimKardashian", "justinbieber", "taylorswift13",
	"espn", "JoelEmbiid", "cstonehoops", "KUHoops",
	"upshotnyt", "fivethirtyeight", "hadleywickham",
	"cnn", "foxnews", "msnbc", "maddow", "seanhannity", 
	"potus", "epa", "hillaryclinton", "realdonaldtrump", 
	"natesilver538", "ezraklein", "annecoulter")
famous_tweeters <- lookup_users(users)
famous_tweeters

# extract most recent tweets data from the famous tweeters
tweets_data(famous_tweeters)

# or get user IDs of people following stephen colbert
colbert_nation <- get_followers("stephenathome", n = 18000)

# get even more by using the next_cursor function
page <- next_cursor(colbert_nation)

# use the page object to continue where you left off
colbert_nation_ii <- get_followers("stephenathome", n = 18000, page = page)
colbert_nation <- c(unlist(colbert_nation), unlist(colbert_nation_ii))

# and then lookup data on those users (if hit rate limit, run as two parts)
colbert_nation <- lookup_users(colbert_nation)
colbert_nation

# or get user IDs of people followed *by* President Obama
obama1 <- get_friends("BarackObama")
obama2 <- get_friends("BarackObama", page = next_cursor(obama1))

# and lookup data on Obama's friends
lookup_users(c(unlist(obama1), unlist(obama2)))
```

## Retrieving Trends

```{r, eval=FALSE}
# get trending hashtags, mentions, and topics worldwide
prestige_worldwide <- get_trends()
prestige_worldwide

# or narrow down to a particular country
usa_usa_usa <- get_trends("United States")
usa_usa_usa

# or narrow down to a popular city
CHIEFS <- get_trends("Kansas City")
CHIEFS
```
